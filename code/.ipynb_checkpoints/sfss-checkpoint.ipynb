{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sebastian Raschka\n",
    "# last updated: 03/29/2014 \n",
    "# Sequential Floating Forward Selection (SFFS)\n",
    "\n",
    "def seq_float_forw_select(features, max_k, criterion_func, print_steps=False):\n",
    "    \"\"\"\n",
    "    Implementation of Sequential Floating Forward Selection.\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        features (list): The feature space as a list of features.\n",
    "        max_k: Termination criterion; the size of the returned feature subset.\n",
    "        criterion_func (function): Function that is used to evaluate the\n",
    "            performance of the feature subset.\n",
    "        print_steps (bool): Prints the algorithm procedure if True.\n",
    "    \n",
    "    Returns the selected feature subset, a list of features of length max_k.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialization\n",
    "    feat_sub = []\n",
    "    k = 0\n",
    "\n",
    "    while True:\n",
    "\n",
    "        # Step 1: Inclusion\n",
    "        if print_steps:\n",
    "            print('\\nInclusion from features', features)\n",
    "        if len(features) > 0:\n",
    "            crit_func_max = criterion_func(feat_sub + [features[0]])\n",
    "            best_feat = features[0]\n",
    "            if len(features) > 1:\n",
    "                for x in features[1:]:\n",
    "                    crit_func_eval = criterion_func(feat_sub + [x])\n",
    "                    if crit_func_eval > crit_func_max:\n",
    "                        crit_func_max = crit_func_eval\n",
    "                        best_feat = x\n",
    "            features.remove(best_feat)\n",
    "            feat_sub.append(best_feat)\n",
    "            if print_steps:\n",
    "                print('include: {} -> feature_subset: {}'.format(best_feat, feat_sub))\n",
    "\n",
    "        # Step 2: Conditional Exclusion\n",
    "            worst_feat_val = None\n",
    "            if len(features) + len(feat_sub) > max_k:\n",
    "                crit_func_max = criterion_func(feat_sub)\n",
    "                for i in reversed(range(0,len(feat_sub))):\n",
    "                    crit_func_eval = criterion_func(feat_sub[:i] + feat_sub[i+1:])\n",
    "                    if crit_func_eval > crit_func_max:\n",
    "                        worst_feat, crit_func_max = i, crit_func_eval\n",
    "                        worst_feat_val = feat_sub[worst_feat]\n",
    "                if worst_feat_val:\n",
    "                    del feat_sub[worst_feat]\n",
    "            if print_steps:\n",
    "                print('exclude: {} -> feature subset: {}'.format(worst_feat_val, feat_sub))\n",
    "\n",
    "\n",
    "        # Termination condition\n",
    "        k = len(feat_sub)\n",
    "        if k == max_k:\n",
    "            break\n",
    "\n",
    "    return feat_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fridge 34\n",
      "hvac 57\n",
      "dr 35\n",
      "light 24\n",
      "dw 31\n",
      "wm 28\n"
     ]
    }
   ],
   "source": [
    "__author__ = 'nipunbatra'\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "df = pd.read_csv(\"../main_15min_decomposition_12_daily_weekly_cluster_diff_frac_temp.csv\",index_col=0)\n",
    "dfc = df.copy()\n",
    "\n",
    "df = df.drop(871)\n",
    "df = df.drop(1169)\n",
    "\n",
    "\n",
    "\n",
    "w=df[['aggregate_%d' %i for i in range(1,13)]]\n",
    "\n",
    "df = df.ix[w[w>0].dropna().index]\n",
    "\n",
    "\"\"\"\n",
    "features_individual = {#'fraction':[\"fraction_%d\" % i for i in range(1, 25)],\n",
    "                       'area': 'area',\n",
    "                       'autocorr':'autocorr',\n",
    "                       'month': [\"aggregate_%d\" % i for i in range(1, 13)],\n",
    "                       'occupants': 'total_occupants',\n",
    "                       'rooms': 'num_rooms',\n",
    "                       #'seasonal_daily':['stdev_seasonal_daily','max_seasonal_daily'],\n",
    "                       #'trend_daily':['stdev_trend_daily','max_trend_daily'],\n",
    "                       'seasonal_weekly':['stdev_seasonal_weekly','max_seasonal_weekly'],\n",
    "                       'trend_weekly':['stdev_trend_weekly','max_trend_weekly'],}\n",
    "                       #'disag_fridge':'disag_fridge'}\n",
    "                       #'mins_hvac':'mins_hvac',}\n",
    "                       #'month_extract':['variance','ratio_min_max', 'difference_min_max',\n",
    "                        #                'ratio_difference_min_max']}\n",
    "\n",
    "\"\"\"\n",
    "features_individual = {#'fraction':[\"fraction_%d\" % i for i in range(1, 25)],\n",
    "                       'area': 'area',\n",
    "                       'autocorr':'autocorr',\n",
    "                       'month': [\"aggregate_%d\" % i for i in range(1, 13)],\n",
    "                       'occupants': 'total_occupants',\n",
    "                       'rooms': 'num_rooms',\n",
    "                       'seasonal_12':['stdev_seasonal_12','max_seasonal_12'],\n",
    "                       'trend_12':['stdev_trend_12','max_trend_12'],\n",
    "\n",
    "                       'seasonal_daily':['stdev_seasonal_daily','max_seasonal_daily'],\n",
    "                       'trend_daily':['stdev_trend_daily','max_trend_daily'],\n",
    "                       'seasonal_weekly':['stdev_seasonal_weekly','max_seasonal_weekly'],\n",
    "                       'trend_weekly':['stdev_trend_weekly','max_trend_weekly'],\n",
    "                       'cluster_big':'cluster_big',\n",
    "                       'cluster_small':'cluster_small',\n",
    "                       'diff':['lt_500','bet_500_1000','gt_1000'],\n",
    "                       'temp':'temperature_corr',\n",
    "                       #'disag_fridge':'disag_fridge'}\n",
    "                       'mins_hvac':'mins_hvac',\n",
    "                       'month_extract':['variance','ratio_min_max', 'difference_min_max',\n",
    "                                        'ratio_difference_min_max']}\n",
    "\n",
    "### Monthly ONLY\n",
    "\"\"\"\n",
    "features_individual = {#'fraction':[\"fraction_%d\" % i for i in range(1, 25)],\n",
    "                       'area': 'area',\n",
    "                       #'autocorr':'autocorr',\n",
    "                       'month': [\"aggregate_%d\" % i for i in range(1, 13)],\n",
    "                       'occupants': 'total_occupants',\n",
    "                       'rooms': 'num_rooms',\n",
    "                       #'seasonal_12':['stdev_seasonal_12','max_seasonal_12'],\n",
    "                       #'trend_12':['stdev_trend_12','max_trend_12'],\n",
    "                       #'seasonal_daily':['stdev_seasonal_daily','max_seasonal_daily'],\n",
    "                       #'trend_daily':['stdev_trend_daily','max_trend_daily'],\n",
    "                       #'seasonal_weekly':['stdev_seasonal_weekly','max_seasonal_weekly'],\n",
    "                       #'trend_weekly':['stdev_trend_weekly','max_trend_weekly'],}\n",
    "                       #'disag_fridge':'disag_fridge'}\n",
    "                       #'mins_hvac':'mins_hvac',\n",
    "                       #'cluster_big':'cluster_big',\n",
    "                       #'diff':['lt_500','bet_500_1000','gt_1000'],\n",
    "                       'temp':'temperature_corr',\n",
    "                       'month_extract':['variance','ratio_min_max', 'difference_min_max',\n",
    "                                        'ratio_difference_min_max']}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from itertools import combinations\n",
    "features_dict = {}\n",
    "for feature_size in range(1,min(4,len(features_individual))):\n",
    "    combinations_size_n = list(combinations(features_individual.keys(), feature_size))\n",
    "    for com in combinations_size_n:\n",
    "        features_dict[com] = np.hstack([features_individual[x] for x in com]).tolist()\n",
    "\n",
    "\n",
    "\n",
    "hvac_fhmm_pred = pd.read_csv(\"../fhmm_disag_new.csv\", index_col=0)\n",
    "fridge_fhmm_pred = pd.read_csv(\"../fridge_fhmm.csv\", index_col=0)\n",
    "appliance_fhmm = {'fridge': fridge_fhmm_pred,\n",
    "                  'hvac': hvac_fhmm_pred}\n",
    "\n",
    "national_average = {\"fridge\": 0.07, \"hvac\": 0.18, 'wm': 0.01, 'furnace': 0.09, 'dw': 0.02, 'dr': 0.04, 'light': .11}\n",
    "\n",
    "\n",
    "#Normalising features\n",
    "max_aggregate = df[[\"aggregate_%d\" % i for i in range(1, 13)]].max().max()\n",
    "df[[\"aggregate_%d\" % i for i in range(1, 13)]] = df[[\"aggregate_%d\" % i for i in range(1, 13)]].div(max_aggregate)\n",
    "\n",
    "df['area'] = df['area'].div(df['area'].max())\n",
    "\n",
    "df['num_rooms'] = df['num_rooms'].div(df['num_rooms'].max())\n",
    "df['total_occupants'] = df['total_occupants'].div(df['total_occupants'].max())\n",
    "df['mins_hvac'] =  df['mins_hvac'].div(df['mins_hvac'].max())\n",
    "\n",
    "max_cols = {}\n",
    "for col in [\"stdev_trend_12\",\"stdev_seasonal_12\",\"max_seasonal_12\",\"max_trend_12\",\n",
    "            \"stdev_trend_daily\",\"stdev_seasonal_daily\",\"max_seasonal_daily\",\"max_trend_daily\",\n",
    "            \"stdev_trend_weekly\",\"stdev_seasonal_weekly\",\"max_seasonal_weekly\",\"max_trend_weekly\",\"disag_fridge\",\n",
    "            'stdev_trend','stdev_seasonal','max_seasonal','max_trend',\n",
    "            'cluster_small','cluster_big', 'temperature_corr']:\n",
    "    if col in df.columns:\n",
    "        max_cols[col] = dfc[col].max()\n",
    "        df[col] = df[col].div(df[col].max())\n",
    "\n",
    "\n",
    "# Adding new feature\n",
    "aa = df[[\"aggregate_%d\" % i for i in range(1, 13)]].copy()\n",
    "df['variance'] = df[[\"aggregate_%d\" % i for i in range(1, 13)]].var(axis=1)\n",
    "df['ratio_min_max'] = aa.min(axis=1)/aa.max(axis=1)\n",
    "\n",
    "df['difference_min_max'] = aa.max(axis=1)-aa.min(axis=1)\n",
    "df['ratio_difference_min_max'] = (aa.max(axis=1)-aa.min(axis=1)).div(aa.max(axis=1))\n",
    "\n",
    "dfs = {}\n",
    "total = features_dict.values()[np.array(map(len, features_dict.values())).argmax()]\n",
    "for appliance in ['fridge','hvac','dr','light','dw','wm']:\n",
    "    temp=df.ix[df[['%s_%d' %(appliance, i) for i in range(1,13)]].dropna().index]\n",
    "    dfs[appliance] =temp.ix[temp[total].dropna().index]\n",
    "    print appliance, len(dfs[appliance])\n",
    "\n",
    "appliance_min = {'fridge':5,'hvac':5,'wm':0,'dw':0,'dr':0,'light':0}\n",
    "\n",
    "all_homes = {\n",
    "    'dw':[  94,  370,  545,  624, 2156, 2242, 2814, 2829, 3723,\n",
    "            4767, 5357,6636, 6910, 7769, 9934],\n",
    "    'wm':[  94,  370,  545,  624, 2156, 2242, 2814, 3367, 3456, 3723, 3967,\n",
    "            5357, 7769, 9654, 9922, 9934],\n",
    "    'hvac':[  26,   94,  370,  410,  545,  624, 1283, 1642, 1953, 2129,\n",
    "            2156, 2242, 2470, 2814, 2829,  3367, 3456, 3723,\n",
    "            3967, 4767, 5218, 5357, 5371, 5746, 5785, 5814, 6072,\n",
    "            6636, 6836, 6910, 7731, 7769, 7866, 9609, 9654, 9922, 9933, 9934],\n",
    "    'fridge':[  94,  370,  410,  545,  624, 1953, 2156, 2242, 2814, 2829, 3367,\n",
    "            3456, 3723, 3967, 4767, 5357, 5371, 6072, 6636, 6910, 7769, 7866],\n",
    "    'light':df.index.tolist(),\n",
    "        #[ 624, 1334, 2814, 2925, 2986, 3367, 3456, 3482, 3723, 3967, 4732,\n",
    "        #    4767, 5814, 5817, 6072, 6266, 6910, 7016, 7429, 7731, 7769, 7866,\n",
    "        #    8317, 8626, 9052, 9654, 9922],\n",
    "    'dr':[  94,  370,  410, 2156, 2242, 2814, 3456, 3723, 4767,\n",
    "            5785, 5814, 6072, 6636, 6836, 7731, 7769, 7866, 9654, 9922,\n",
    "            9933, 9982]\n",
    "}\n",
    "\n",
    "all_homes = {appliance:dfs[appliance].index for appliance in dfs.keys()}\n",
    "\n",
    "all_homes['fridge'] = np.array(np.setdiff1d(all_homes['fridge'], [2233, 5746, 7016]))\n",
    "all_homes['hvac'] = np.array(np.setdiff1d(all_homes['hvac'], [252, 2925, 2986, 3482, 4732, 5439, 6266,\n",
    "                                                              8626, 1800, 2233, 5817, 7016, 7429, 8317,\n",
    "                                                              9052, 9982]))\n",
    "\n",
    "all_homes['dw'] =  np.array(np.setdiff1d(all_homes['dw'],[2233, 7016]))\n",
    "\n",
    "\n",
    "def create_predictions(appliance=\"hvac\", feature=['num_rooms', 'total_occupants'],k=2, weights='uniform'):\n",
    "    print \"IN THIS BLOCK\"\n",
    "    print feature\n",
    "    out_month = {}\n",
    "    gt_month = {}\n",
    "    overall_dfs = {}\n",
    "    df_pred_copy = df.copy()\n",
    "    #df_pred_copy = dfs[appliance].copy()\n",
    "    df_pred_copy = df_pred_copy.ix[all_homes[appliance]]\n",
    "    for i, month in enumerate([\"%s_%d\" %(appliance,i) for i in range(1,13)]):\n",
    "        y = df_pred_copy[month]\n",
    "        y2 = y.dropna()\n",
    "        y3 = y2[y2>appliance_min[appliance]].dropna()\n",
    "        df3 = df_pred_copy[feature].ix[y3.index].dropna()\n",
    "        \n",
    "        #df3 = df.ix[y3.index].dropna()\n",
    "        y3 = y3.ix[df3.index]\n",
    "        #df3 = df3.ix[appliance_fhmm[appliance].index].dropna()\n",
    "        #y3 = y3.ix[df3.index]\n",
    "        from sklearn.cross_validation import LeaveOneOut\n",
    "        from sklearn.neighbors import RadiusNeighborsRegressor\n",
    "        #clf = RadiusNeighborsRegressor(radius=k)\n",
    "        clf = KNeighborsRegressor(n_neighbors=k, weights=weights)\n",
    "        #clf = KNeighborsRegressor(n_neighbors=k, weights = 'distance' )\n",
    "        loo = LeaveOneOut(len(df3))\n",
    "        out_pred = []\n",
    "\n",
    "        for train, test in loo:\n",
    "            #clf.fit(preprocessing.normalize(df3[feature_columns[feature]].values[train]), y3.values[train])\n",
    "            clf.fit(df3[feature].values[train], y3.values[train])\n",
    "            #out_pred.append(clf.predict(preprocessing.normalize(df3[feature_columns[feature]].values[test])))\n",
    "            out_pred.append(clf.predict(df3[feature].values[test]))\n",
    "\n",
    "        out_pred = np.hstack(out_pred)\n",
    "\n",
    "        out_month[i+1] = out_pred\n",
    "        gt_month[i+1] = y3.values\n",
    "        overall_dfs[i+1] = pd.DataFrame({\"gt\":y3.values, \"pred\":out_pred,\n",
    "                                              \"gt_total\":dfc.ix[y3.index][\"aggregate_\"+str(i+1)].values}, index=y3.index)\n",
    "        overall_dfs[i+1][\"national average\"] = overall_dfs[i+1][\"gt_total\"]*national_average[appliance]\n",
    "    return overall_dfs\n",
    "\n",
    "def percentage_error(gt, pred):\n",
    "    return 100*np.abs(gt-pred)/(gt)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_metrics(df):\n",
    "    temp = df[df.gt_total>0.0]\n",
    "    temp = temp[temp.gt>temp.gt_total]\n",
    "    return {\"Percentage error in appliance energy\":np.median(percentage_error(df[\"gt\"], df[\"pred\"]))\n",
    "            }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def criterion_function(feature_set):\n",
    "    \n",
    "    k=1\n",
    "    appliance=\"hvac\"\n",
    "    temp = create_predictions(appliance, feature_set, k)\n",
    "    errors = {}\n",
    "    for i in range(1, 13):\n",
    "        errors[i] = percentage_error(temp[i][\"gt\"], temp[i][\"pred\"])\n",
    "    error_df = pd.DataFrame(errors)\n",
    "    accur_df = 100-error_df\n",
    "    accur_df[accur_df<0]=0\n",
    "   \n",
    "    if appliance is \"hvac\":\n",
    "         tdf = accur_df[range(5, 11)]\n",
    "    else:\n",
    "        tdf = accur_df\n",
    "    print tdf.dropna().median().mean()\n",
    "    return tdf.dropna().median().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\nInclusion from features', ['area', 'autocorr', 'temperature_corr', 'total_occupants', 'num_rooms'])\n",
      "IN THIS BLOCK\n",
      "['area']\n",
      "62.6659668625\n",
      "IN THIS BLOCK\n",
      "['autocorr']\n",
      "52.7725688538\n",
      "IN THIS BLOCK\n",
      "['temperature_corr']\n",
      "56.5084909322\n",
      "IN THIS BLOCK\n",
      "['total_occupants']\n",
      "20.5161972056\n",
      "IN THIS BLOCK\n",
      "['num_rooms']\n",
      "39.5001105926\n",
      "include: area -> feature_subset: ['area']\n",
      "IN THIS BLOCK\n",
      "['area']\n",
      "62.6659668625\n",
      "IN THIS BLOCK\n",
      "[]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 feature(s) (shape=(13, 0)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-1c4b2f08ffc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m seq_float_forw_select(features=['area','autocorr', 'temperature_corr','total_occupants','num_rooms'], max_k=1,\n\u001b[0;32m----> 2\u001b[0;31m                       criterion_func=criterion_function, print_steps=True)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-8c58ae98ef95>\u001b[0m in \u001b[0;36mseq_float_forw_select\u001b[0;34m(features, max_k, criterion_func, print_steps)\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mcrit_func_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_sub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_sub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                     \u001b[0mcrit_func_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_sub\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfeat_sub\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mcrit_func_eval\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mcrit_func_max\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                         \u001b[0mworst_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrit_func_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrit_func_eval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-e6c73464f878>\u001b[0m in \u001b[0;36mcriterion_function\u001b[0;34m(feature_set)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mappliance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"hvac\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mappliance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-39c817d8ce93>\u001b[0m in \u001b[0;36mcreate_predictions\u001b[0;34m(appliance, feature, k, weights)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;31m#clf.fit(preprocessing.normalize(df3[feature_columns[feature]].values[train]), y3.values[train])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m             \u001b[0;31m#out_pred.append(clf.predict(preprocessing.normalize(df3[feature_columns[feature]].values[test])))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mout_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nipunbatra/anaconda/lib/python2.7/site-packages/sklearn/neighbors/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    756\u001b[0m         \"\"\"\n\u001b[1;32m    757\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nipunbatra/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    508\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    509\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    511\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/Users/nipunbatra/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    413\u001b[0m                              \u001b[0;34m\" a minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                              % (n_features, shape_repr, ensure_min_features,\n\u001b[0;32m--> 415\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwarn_on_dtype\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype_orig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdtype_orig\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 feature(s) (shape=(13, 0)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "seq_float_forw_select(features=['area','autocorr', 'temperature_corr','total_occupants','num_rooms'], max_k=1,\n",
    "                      criterion_func=criterion_function, print_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seq_forw_select(features, max_k, criterion_func, print_steps=False):\n",
    "    \"\"\"\n",
    "    Implementation of a Sequential Forward Selection algorithm.\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        features (list): The feature space as a list of features.\n",
    "        max_k: Termination criterion; the size of the returned feature subset.\n",
    "        criterion_func (function): Function that is used to evaluate the\n",
    "            performance of the feature subset.\n",
    "        print_steps (bool): Prints the algorithm procedure if True.\n",
    "    \n",
    "    Returns the selected feature subset, a list of features of length max_k.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialization\n",
    "    feat_sub = []\n",
    "    k = 0\n",
    "    d = len(features)\n",
    "    if max_k > d:\n",
    "        max_k = d\n",
    "\n",
    "    while True:\n",
    "\n",
    "        # Inclusion step\n",
    "        if print_steps:\n",
    "            print('\\nInclusion from feature space', features)\n",
    "        crit_func_max = criterion_func(feat_sub + [features[0]])\n",
    "        best_feat = features[0]\n",
    "        for x in features[1:]:\n",
    "            crit_func_eval = criterion_func(feat_sub + [x])\n",
    "            if crit_func_eval > crit_func_max:\n",
    "                crit_func_max = crit_func_eval\n",
    "                best_feat = x\n",
    "        feat_sub.append(best_feat)\n",
    "        if print_steps:\n",
    "            print('include: {} -> feature subset: {}'.format(best_feat, feat_sub))\n",
    "        features.remove(best_feat)\n",
    "\n",
    "        # Termination condition\n",
    "        k = len(feat_sub)\n",
    "        if k == max_k:\n",
    "            break\n",
    "\n",
    "    return feat_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\nInclusion from features', ['autocorr', 'temperature_corr', 'total_occupants', 'num_rooms', 'area', 'aggregate_1'])\n",
      "IN THIS BLOCK\n",
      "['autocorr']\n",
      "52.7725688538\n",
      "IN THIS BLOCK\n",
      "['temperature_corr']\n",
      "56.5084909322\n",
      "IN THIS BLOCK\n",
      "['total_occupants']\n",
      "20.5161972056\n",
      "IN THIS BLOCK\n",
      "['num_rooms']\n",
      "39.5001105926\n",
      "IN THIS BLOCK\n",
      "['area']\n",
      "62.6659668625\n",
      "IN THIS BLOCK\n",
      "['aggregate_1']\n",
      "60.6085118348\n",
      "include: area -> feature_subset: ['area']\n",
      "IN THIS BLOCK\n",
      "['area']\n",
      "62.6659668625\n",
      "IN THIS BLOCK\n",
      "[]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 feature(s) (shape=(13, 0)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-e1299b9196d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m seq_float_forw_select(features=['autocorr', 'temperature_corr','total_occupants','num_rooms','area', 'aggregate_1'], max_k=4,\n\u001b[0;32m----> 2\u001b[0;31m                       criterion_func=criterion_function, print_steps=True)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-8c58ae98ef95>\u001b[0m in \u001b[0;36mseq_float_forw_select\u001b[0;34m(features, max_k, criterion_func, print_steps)\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mcrit_func_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_sub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_sub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                     \u001b[0mcrit_func_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_sub\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfeat_sub\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mcrit_func_eval\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mcrit_func_max\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                         \u001b[0mworst_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrit_func_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrit_func_eval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-e6c73464f878>\u001b[0m in \u001b[0;36mcriterion_function\u001b[0;34m(feature_set)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mappliance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"hvac\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mappliance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-39c817d8ce93>\u001b[0m in \u001b[0;36mcreate_predictions\u001b[0;34m(appliance, feature, k, weights)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;31m#clf.fit(preprocessing.normalize(df3[feature_columns[feature]].values[train]), y3.values[train])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m             \u001b[0;31m#out_pred.append(clf.predict(preprocessing.normalize(df3[feature_columns[feature]].values[test])))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mout_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nipunbatra/anaconda/lib/python2.7/site-packages/sklearn/neighbors/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    756\u001b[0m         \"\"\"\n\u001b[1;32m    757\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nipunbatra/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    508\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    509\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    511\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/Users/nipunbatra/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    413\u001b[0m                              \u001b[0;34m\" a minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                              % (n_features, shape_repr, ensure_min_features,\n\u001b[0;32m--> 415\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwarn_on_dtype\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype_orig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdtype_orig\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 feature(s) (shape=(13, 0)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "seq_float_forw_select(features=['autocorr', 'temperature_corr','total_occupants','num_rooms','area', 'aggregate_1'], max_k=4,\n",
    "                      criterion_func=criterion_function, print_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def seq_backw_select(features, max_k, criterion_func, print_steps=False):\n",
    "    \"\"\"\n",
    "    Implementation of a Sequential Backward Selection algorithm.\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        features (list): The feature space as a list of features.\n",
    "        max_k: Termination criterion; the size of the returned feature subset.\n",
    "        criterion_func (function): Function that is used to evaluate the\n",
    "            performance of the feature subset.\n",
    "        print_steps (bool): Prints the algorithm procedure if True.\n",
    "        \n",
    "    Returns the selected feature subset, a list of features of length max_k.\n",
    "\n",
    "    \"\"\"\n",
    "    # Initialization\n",
    "    feat_sub = deepcopy(features)\n",
    "    k = len(feat_sub)\n",
    "    i = 0\n",
    "\n",
    "    while True:\n",
    "\n",
    "        # Exclusion step\n",
    "        if print_steps:\n",
    "            print('\\nExclusion from feature subset', feat_sub)\n",
    "        worst_feat = len(feat_sub)-1\n",
    "        worst_feat_val = feat_sub[worst_feat]\n",
    "        crit_func_max = criterion_func(feat_sub[:-1])\n",
    "\n",
    "        for i in reversed(range(0,len(feat_sub)-1)):\n",
    "            crit_func_eval = criterion_func(feat_sub[:i] + feat_sub[i+1:])\n",
    "            if crit_func_eval > crit_func_max:\n",
    "                worst_feat, crit_func_max = i, crit_func_eval\n",
    "                worst_feat_val = feat_sub[worst_feat]\n",
    "        del feat_sub[worst_feat]\n",
    "        if print_steps:\n",
    "            print('exclude: {} -> feature subset: {}'.format(worst_feat_val, feat_sub))\n",
    "\n",
    "        # Termination condition\n",
    "        k = len(feat_sub)\n",
    "        if k == max_k:\n",
    "            break\n",
    "\n",
    "    return feat_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\nExclusion from feature subset', ['autocorr', 'temperature_corr', 'total_occupants', 'num_rooms', 'area', 'aggregate_1'])\n",
      "IN THIS BLOCK\n",
      "['autocorr', 'temperature_corr', 'total_occupants', 'num_rooms', 'area']\n",
      "60.7848622505\n",
      "IN THIS BLOCK\n",
      "['autocorr', 'temperature_corr', 'total_occupants', 'num_rooms', 'aggregate_1']\n",
      "59.1731614297\n",
      "IN THIS BLOCK\n",
      "['autocorr', 'temperature_corr', 'total_occupants', 'area', 'aggregate_1']\n",
      "60.4731194239\n",
      "IN THIS BLOCK\n",
      "['autocorr', 'temperature_corr', 'num_rooms', 'area', 'aggregate_1']\n",
      "58.5853586772\n",
      "IN THIS BLOCK\n",
      "['autocorr', 'total_occupants', 'num_rooms', 'area', 'aggregate_1']\n",
      "58.1013026508\n",
      "IN THIS BLOCK\n",
      "['temperature_corr', 'total_occupants', 'num_rooms', 'area', 'aggregate_1']\n",
      "59.5159888871\n",
      "exclude: aggregate_1 -> feature subset: ['autocorr', 'temperature_corr', 'total_occupants', 'num_rooms', 'area']\n",
      "('\\nExclusion from feature subset', ['autocorr', 'temperature_corr', 'total_occupants', 'num_rooms', 'area'])\n",
      "IN THIS BLOCK\n",
      "['autocorr', 'temperature_corr', 'total_occupants', 'num_rooms']\n",
      "51.6173459119\n",
      "IN THIS BLOCK\n",
      "['autocorr', 'temperature_corr', 'total_occupants', 'area']\n",
      "58.1076961215\n",
      "IN THIS BLOCK\n",
      "['autocorr', 'temperature_corr', 'num_rooms', 'area']\n",
      "60.6722048117\n",
      "IN THIS BLOCK\n",
      "['autocorr', 'total_occupants', 'num_rooms', 'area']\n",
      "59.9377620881\n",
      "IN THIS BLOCK\n",
      "['temperature_corr', 'total_occupants', 'num_rooms', 'area']\n",
      "59.8576199885\n",
      "exclude: total_occupants -> feature subset: ['autocorr', 'temperature_corr', 'num_rooms', 'area']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['autocorr', 'temperature_corr', 'num_rooms', 'area']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_backw_select(features=['autocorr', 'temperature_corr','total_occupants','num_rooms','area', 'aggregate_1'], max_k=4,\n",
    "                      criterion_func=criterion_function, print_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN THIS BLOCK\n",
      "['fraction_1' 'fraction_2' 'fraction_3' 'fraction_4' 'fraction_5'\n",
      " 'fraction_6' 'fraction_7' 'fraction_8' 'fraction_9' 'fraction_10'\n",
      " 'fraction_11' 'fraction_12' 'fraction_13' 'fraction_14' 'fraction_15'\n",
      " 'fraction_16' 'fraction_17' 'fraction_18' 'fraction_19' 'fraction_20'\n",
      " 'fraction_21' 'fraction_22' 'fraction_23' 'fraction_24' 'autocorr'\n",
      " 'max_seasonal_12' 'stdev_seasonal_12' 'max_trend_12' 'stdev_trend_12'\n",
      " 'max_seasonal_daily' 'stdev_seasonal_daily' 'max_trend_daily'\n",
      " 'stdev_trend_daily' 'max_seasonal_weekly' 'stdev_seasonal_weekly'\n",
      " 'max_trend_weekly' 'stdev_trend_weekly' 'disag_fridge' 'cluster_small'\n",
      " 'cluster_big' 'lt_500' 'bet_500_1000' 'gt_1000' 'temperature_corr']\n",
      "66.1889825289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "66.188982528901349"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion_function(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.hstack([\n",
    "            [\"fraction_%d\" %i for i in range(1,25)],\n",
    "         \"autocorr\",\n",
    "         \"max_seasonal_12\",\n",
    "        \"stdev_seasonal_12\",\n",
    "        \"max_trend_12\",\n",
    "        \"stdev_trend_12\",\n",
    "        \"max_seasonal_daily\",\n",
    "        \"stdev_seasonal_daily\",\n",
    "        \"max_trend_daily\",\n",
    "        \"stdev_trend_daily\",\n",
    "         \"max_seasonal_weekly\",\n",
    "        \"stdev_seasonal_weekly\",\n",
    "        \"max_trend_weekly\",\n",
    "        \"stdev_trend_weekly\",\n",
    "        \"disag_fridge\",\n",
    "        \"cluster_small\",\n",
    "        \"cluster_big\",\n",
    "        \"lt_500\",\n",
    "        \"bet_500_1000\",\n",
    "        \"gt_1000\",\n",
    "        \"temperature_corr\"\n",
    "\n",
    "           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fraction_1', 'fraction_2', 'fraction_3', 'fraction_4',\n",
       "       'fraction_5', 'fraction_6', 'fraction_7', 'fraction_8',\n",
       "       'fraction_9', 'fraction_10', 'fraction_11', 'fraction_12',\n",
       "       'fraction_13', 'fraction_14', 'fraction_15', 'fraction_16',\n",
       "       'fraction_17', 'fraction_18', 'fraction_19', 'fraction_20',\n",
       "       'fraction_21', 'fraction_22', 'fraction_23', 'fraction_24',\n",
       "       'autocorr', 'max_seasonal_12', 'stdev_seasonal_12', 'max_trend_12',\n",
       "       'stdev_trend_12', 'max_seasonal_daily', 'stdev_seasonal_daily',\n",
       "       'max_trend_daily', 'stdev_trend_daily', 'max_seasonal_weekly',\n",
       "       'stdev_seasonal_weekly', 'max_trend_weekly', 'stdev_trend_weekly',\n",
       "       'disag_fridge', 'cluster_small', 'cluster_big', 'lt_500',\n",
       "       'bet_500_1000', 'gt_1000', 'temperature_corr'], \n",
       "      dtype='|S21')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
