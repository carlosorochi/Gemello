{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fridge 34\n",
      "hvac 57\n",
      "dr 35\n",
      "light 24\n",
      "dw 31\n",
      "wm 28\n"
     ]
    }
   ],
   "source": [
    "__author__ = 'nipunbatra'\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "df = pd.read_csv(\"../main_15min_decomposition_12_daily_weekly_cluster_diff_frac_temp_weekday.csv\",index_col=0)\n",
    "dfc = df.copy()\n",
    "\n",
    "df = df.drop(871)\n",
    "df = df.drop(1169)\n",
    "\n",
    "\n",
    "\n",
    "w=df[['aggregate_%d' %i for i in range(1,13)]]\n",
    "\n",
    "df = df.ix[w[w>0].dropna().index]\n",
    "\n",
    "\"\"\"\n",
    "features_individual = {#'fraction':[\"fraction_%d\" % i for i in range(1, 25)],\n",
    "                       'area': 'area',\n",
    "                       'autocorr':'autocorr',\n",
    "                       'month': [\"aggregate_%d\" % i for i in range(1, 13)],\n",
    "                       'occupants': 'total_occupants',\n",
    "                       'rooms': 'num_rooms',\n",
    "                       #'seasonal_daily':['stdev_seasonal_daily','max_seasonal_daily'],\n",
    "                       #'trend_daily':['stdev_trend_daily','max_trend_daily'],\n",
    "                       'seasonal_weekly':['stdev_seasonal_weekly','max_seasonal_weekly'],\n",
    "                       'trend_weekly':['stdev_trend_weekly','max_trend_weekly'],}\n",
    "                       #'disag_fridge':'disag_fridge'}\n",
    "                       #'mins_hvac':'mins_hvac',}\n",
    "                       #'month_extract':['variance','ratio_min_max', 'difference_min_max',\n",
    "                        #                'ratio_difference_min_max']}\n",
    "\n",
    "\"\"\"\n",
    "features_individual = {#'fraction':[\"fraction_%d\" % i for i in range(1, 25)],\n",
    "                       'area': 'area',\n",
    "                       'autocorr':'autocorr',\n",
    "                       'month': [\"aggregate_%d\" % i for i in range(1, 13)],\n",
    "                       'occupants': 'total_occupants',\n",
    "                       'rooms': 'num_rooms',\n",
    "                       'seasonal_12':['stdev_seasonal_12','max_seasonal_12'],\n",
    "                       'trend_12':['stdev_trend_12','max_trend_12'],\n",
    "\n",
    "                       'seasonal_daily':['stdev_seasonal_daily','max_seasonal_daily'],\n",
    "                       'trend_daily':['stdev_trend_daily','max_trend_daily'],\n",
    "                       'seasonal_weekly':['stdev_seasonal_weekly','max_seasonal_weekly'],\n",
    "                       'trend_weekly':['stdev_trend_weekly','max_trend_weekly'],\n",
    "                       'cluster_big':'cluster_big',\n",
    "                       'cluster_small':'cluster_small',\n",
    "                       'diff':['lt_500','bet_500_1000','gt_1000'],\n",
    "                       'temp':'temperature_corr',\n",
    "                       #'disag_fridge':'disag_fridge'}\n",
    "                       'mins_hvac':'mins_hvac',\n",
    "                       'month_extract':['variance','ratio_min_max', 'difference_min_max',\n",
    "                                        'ratio_difference_min_max']}\n",
    "\n",
    "### Monthly ONLY\n",
    "\"\"\"\n",
    "features_individual = {#'fraction':[\"fraction_%d\" % i for i in range(1, 25)],\n",
    "                       'area': 'area',\n",
    "                       #'autocorr':'autocorr',\n",
    "                       'month': [\"aggregate_%d\" % i for i in range(1, 13)],\n",
    "                       'occupants': 'total_occupants',\n",
    "                       'rooms': 'num_rooms',\n",
    "                       #'seasonal_12':['stdev_seasonal_12','max_seasonal_12'],\n",
    "                       #'trend_12':['stdev_trend_12','max_trend_12'],\n",
    "                       #'seasonal_daily':['stdev_seasonal_daily','max_seasonal_daily'],\n",
    "                       #'trend_daily':['stdev_trend_daily','max_trend_daily'],\n",
    "                       #'seasonal_weekly':['stdev_seasonal_weekly','max_seasonal_weekly'],\n",
    "                       #'trend_weekly':['stdev_trend_weekly','max_trend_weekly'],}\n",
    "                       #'disag_fridge':'disag_fridge'}\n",
    "                       #'mins_hvac':'mins_hvac',\n",
    "                       #'cluster_big':'cluster_big',\n",
    "                       #'diff':['lt_500','bet_500_1000','gt_1000'],\n",
    "                       'temp':'temperature_corr',\n",
    "                       'month_extract':['variance','ratio_min_max', 'difference_min_max',\n",
    "                                        'ratio_difference_min_max']}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from itertools import combinations\n",
    "features_dict = {}\n",
    "for feature_size in range(1,min(4,len(features_individual))):\n",
    "    combinations_size_n = list(combinations(features_individual.keys(), feature_size))\n",
    "    for com in combinations_size_n:\n",
    "        features_dict[com] = np.hstack([features_individual[x] for x in com]).tolist()\n",
    "\n",
    "\n",
    "\n",
    "hvac_fhmm_pred = pd.read_csv(\"../fhmm_disag_new.csv\", index_col=0)\n",
    "fridge_fhmm_pred = pd.read_csv(\"../fridge_fhmm.csv\", index_col=0)\n",
    "appliance_fhmm = {'fridge': fridge_fhmm_pred,\n",
    "                  'hvac': hvac_fhmm_pred}\n",
    "\n",
    "national_average = {\"fridge\": 0.07, \"hvac\": 0.18, 'wm': 0.01, 'furnace': 0.09, 'dw': 0.02, 'dr': 0.04, 'light': .11}\n",
    "\n",
    "\n",
    "#Normalising features\n",
    "max_aggregate = df[[\"aggregate_%d\" % i for i in range(1, 13)]].max().max()\n",
    "df[[\"aggregate_%d\" % i for i in range(1, 13)]] = df[[\"aggregate_%d\" % i for i in range(1, 13)]].div(max_aggregate)\n",
    "\n",
    "max_weekly = df[[\"daily_usage_%d\" % i for i in range(1, 8)]].max().max()\n",
    "df[[\"daily_usage_%d\" % i for i in range(1, 8)]] = df[[\"daily_usage_%d\" % i for i in range(1, 8)]].div(max_weekly)\n",
    "\n",
    "\n",
    "df['area'] = df['area'].div(df['area'].max())\n",
    "\n",
    "df['num_rooms'] = df['num_rooms'].div(df['num_rooms'].max())\n",
    "df['total_occupants'] = df['total_occupants'].div(df['total_occupants'].max())\n",
    "df['mins_hvac'] =  df['mins_hvac'].div(df['mins_hvac'].max())\n",
    "\n",
    "max_cols = {}\n",
    "for col in [\"stdev_trend_12\",\"stdev_seasonal_12\",\"max_seasonal_12\",\"max_trend_12\",\n",
    "            \"stdev_trend_daily\",\"stdev_seasonal_daily\",\"max_seasonal_daily\",\"max_trend_daily\",\n",
    "            \"stdev_trend_weekly\",\"stdev_seasonal_weekly\",\"max_seasonal_weekly\",\"max_trend_weekly\",\"disag_fridge\",\n",
    "            'stdev_trend','stdev_seasonal','max_seasonal','max_trend',\n",
    "            'cluster_small','cluster_big', 'temperature_corr']:\n",
    "    if col in df.columns:\n",
    "        max_cols[col] = dfc[col].max()\n",
    "        df[col] = df[col].div(df[col].max())\n",
    "\n",
    "\n",
    "# Adding new feature\n",
    "aa = df[[\"aggregate_%d\" % i for i in range(1, 13)]].copy()\n",
    "df['variance'] = df[[\"aggregate_%d\" % i for i in range(1, 13)]].var(axis=1)\n",
    "df['ratio_min_max'] = aa.min(axis=1)/aa.max(axis=1)\n",
    "\n",
    "df['difference_min_max'] = aa.max(axis=1)-aa.min(axis=1)\n",
    "df['ratio_difference_min_max'] = (aa.max(axis=1)-aa.min(axis=1)).div(aa.max(axis=1))\n",
    "\n",
    "dfs = {}\n",
    "total = features_dict.values()[np.array(map(len, features_dict.values())).argmax()]\n",
    "for appliance in ['fridge','hvac','dr','light','dw','wm']:\n",
    "    temp=df.ix[df[['%s_%d' %(appliance, i) for i in range(1,13)]].dropna().index]\n",
    "    dfs[appliance] =temp.ix[temp[total].dropna().index]\n",
    "    print appliance, len(dfs[appliance])\n",
    "\n",
    "appliance_min = {'fridge':5,'hvac':5,'wm':0,'dw':0,'dr':0,'light':0}\n",
    "\n",
    "all_homes = {\n",
    "    'dw':[  94,  370,  545,  624, 2156, 2242, 2814, 2829, 3723,\n",
    "            4767, 5357,6636, 6910, 7769, 9934],\n",
    "    'wm':[  94,  370,  545,  624, 2156, 2242, 2814, 3367, 3456, 3723, 3967,\n",
    "            5357, 7769, 9654, 9922, 9934],\n",
    "    'hvac':[  26,   94,  370,  410,  545,  624, 1283, 1642, 1953, 2129,\n",
    "            2156, 2242, 2470, 2814, 2829,  3367, 3456, 3723,\n",
    "            3967, 4767, 5218, 5357, 5371, 5746, 5785, 5814, 6072,\n",
    "            6636, 6836, 6910, 7731, 7769, 7866, 9609, 9654, 9922, 9933, 9934],\n",
    "    'fridge':[  94,  370,  410,  545,  624, 1953, 2156, 2242, 2814, 2829, 3367,\n",
    "            3456, 3723, 3967, 4767, 5357, 5371, 6072, 6636, 6910, 7769, 7866],\n",
    "    'light':df.index.tolist(),\n",
    "        #[ 624, 1334, 2814, 2925, 2986, 3367, 3456, 3482, 3723, 3967, 4732,\n",
    "        #    4767, 5814, 5817, 6072, 6266, 6910, 7016, 7429, 7731, 7769, 7866,\n",
    "        #    8317, 8626, 9052, 9654, 9922],\n",
    "    'dr':[  94,  370,  410, 2156, 2242, 2814, 3456, 3723, 4767,\n",
    "            5785, 5814, 6072, 6636, 6836, 7731, 7769, 7866, 9654, 9922,\n",
    "            9933, 9982]\n",
    "}\n",
    "\n",
    "all_homes = {appliance:dfs[appliance].index for appliance in dfs.keys()}\n",
    "\n",
    "all_homes['fridge'] = np.array(np.setdiff1d(all_homes['fridge'], [2233, 5746, 7016]))\n",
    "all_homes['hvac'] = np.array(np.setdiff1d(all_homes['hvac'], [252, 2925, 2986, 3482, 4732, 5439, 6266,\n",
    "                                                              8626, 1800, 2233, 5817, 7016, 7429, 8317,\n",
    "                                                              9052, 9982]))\n",
    "\n",
    "all_homes['dw'] =  np.array(np.setdiff1d(all_homes['dw'],[2233, 7016]))\n",
    "all_homes['wm'] = np.array([  94,  370,  545,  624, 2156, 2242, 2470, 2814, 3367, 3456, 3723,\n",
    "            3967, 5357, 7769, 9654, 9922, 9934])\n",
    "\n",
    "\n",
    "def create_predictions(appliance=\"hvac\", feature=['num_rooms', 'total_occupants'],k=2, weights='uniform'):\n",
    "    \n",
    "   \n",
    "    out_month = {}\n",
    "    gt_month = {}\n",
    "    overall_dfs = {}\n",
    "    df_pred_copy = df.copy()\n",
    "    #df_pred_copy = dfs[appliance].copy()\n",
    "    df_pred_copy = df_pred_copy.ix[all_homes[appliance]]\n",
    "    for i, month in enumerate([\"%s_%d\" %(appliance,i) for i in range(1,13)]):\n",
    "        y = df_pred_copy[month]\n",
    "        y2 = y.dropna()\n",
    "        y3 = y2[y2>appliance_min[appliance]].dropna()\n",
    "        df3 = df_pred_copy[feature].ix[y3.index].dropna()\n",
    "        \n",
    "        #df3 = df.ix[y3.index].dropna()\n",
    "        y3 = y3.ix[df3.index]\n",
    "        #df3 = df3.ix[appliance_fhmm[appliance].index].dropna()\n",
    "        #y3 = y3.ix[df3.index]\n",
    "        from sklearn.cross_validation import LeaveOneOut\n",
    "        from sklearn.neighbors import RadiusNeighborsRegressor\n",
    "        #clf = RadiusNeighborsRegressor(radius=k)\n",
    "        clf = KNeighborsRegressor(n_neighbors=k, weights=weights)\n",
    "        #clf = KNeighborsRegressor(n_neighbors=k, weights = 'distance' )\n",
    "        loo = LeaveOneOut(len(df3))\n",
    "        out_pred = []\n",
    "\n",
    "        for train, test in loo:\n",
    "            #clf.fit(preprocessing.normalize(df3[feature_columns[feature]].values[train]), y3.values[train])\n",
    "            clf.fit(df3[feature].values[train], y3.values[train])\n",
    "            #out_pred.append(clf.predict(preprocessing.normalize(df3[feature_columns[feature]].values[test])))\n",
    "            out_pred.append(clf.predict(df3[feature].values[test]))\n",
    "\n",
    "        out_pred = np.hstack(out_pred)\n",
    "\n",
    "        out_month[i+1] = out_pred\n",
    "        gt_month[i+1] = y3.values\n",
    "        overall_dfs[i+1] = pd.DataFrame({\"gt\":y3.values, \"pred\":out_pred,\n",
    "                                              \"gt_total\":dfc.ix[y3.index][\"aggregate_\"+str(i+1)].values}, index=y3.index)\n",
    "        overall_dfs[i+1][\"national average\"] = overall_dfs[i+1][\"gt_total\"]*national_average[appliance]\n",
    "    return overall_dfs\n",
    "\n",
    "def percentage_error(gt, pred):\n",
    "    return 100*np.abs(gt-pred)/(gt)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_metrics(df):\n",
    "    temp = df[df.gt_total>0.0]\n",
    "    temp = temp[temp.gt>temp.gt_total]\n",
    "    return {\"Percentage error in appliance energy\":np.median(percentage_error(df[\"gt\"], df[\"pred\"]))\n",
    "            }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def criterion_function(feature_set):\n",
    "    \n",
    "    \n",
    "    temp = create_predictions(appliance, feature_set, k)\n",
    "    errors = {}\n",
    "    for i in range(1, 13):\n",
    "        errors[i] = percentage_error(temp[i][\"gt\"], temp[i][\"pred\"])\n",
    "    error_df = pd.DataFrame(errors)\n",
    "    accur_df = 100-error_df\n",
    "    accur_df[accur_df<0]=0\n",
    "   \n",
    "    if appliance is \"hvac\":\n",
    "         tdf = accur_df[range(5, 11)]\n",
    "    else:\n",
    "        tdf = accur_df\n",
    "    #print tdf.dropna().median().mean(), feature_set\n",
    "    return tdf.dropna().median().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seq_forw_select(features, max_k, criterion_func, print_steps=False):\n",
    "    \"\"\"\n",
    "    Implementation of a Sequential Forward Selection algorithm.\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        features (list): The feature space as a list of features.\n",
    "        max_k: Termination criterion; the size of the returned feature subset.\n",
    "        criterion_func (function): Function that is used to evaluate the\n",
    "            performance of the feature subset.\n",
    "        print_steps (bool): Prints the algorithm procedure if True.\n",
    "    \n",
    "    Returns the selected feature subset, a list of features of length max_k.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialization\n",
    "    feat_sub = []\n",
    "    k = 0\n",
    "    d = len(features)\n",
    "    if max_k > d:\n",
    "        max_k = d\n",
    "\n",
    "    while True:\n",
    "\n",
    "        # Inclusion step\n",
    "        \n",
    "        crit_func_max = criterion_func(feat_sub + [features[0]])\n",
    "        best_feat = features[0]\n",
    "        for x in features[1:]:\n",
    "            crit_func_eval = criterion_func(feat_sub + [x])\n",
    "            if crit_func_eval > crit_func_max:\n",
    "                crit_func_max = crit_func_eval\n",
    "                best_feat = x\n",
    "        feat_sub.append(best_feat)\n",
    "        if print_steps:\n",
    "            print('include: {} -> feature_subset: {}. Accuracy: {}'.format(best_feat, feat_sub, crit_func_max))\n",
    "        features.remove(best_feat)\n",
    "\n",
    "        # Termination condition\n",
    "        k = len(feat_sub)\n",
    "        if k == max_k:\n",
    "            break\n",
    "\n",
    "    return feat_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.hstack([[\"aggregate_%d\" %i for i in range(1,13)],\n",
    "            [\"fraction_%d\" %i for i in range(1,25)],\n",
    "         \"autocorr\",\n",
    "         \"max_seasonal_12\",\n",
    "        \"stdev_seasonal_12\",\n",
    "        \"max_trend_12\",\n",
    "        \"stdev_trend_12\",\n",
    "        \"max_seasonal_daily\",\n",
    "        \"stdev_seasonal_daily\",\n",
    "        \"max_trend_daily\",\n",
    "        \"stdev_trend_daily\",\n",
    "         \"max_seasonal_weekly\",\n",
    "        \"stdev_seasonal_weekly\",\n",
    "        \"max_trend_weekly\",\n",
    "        \"stdev_trend_weekly\",\n",
    "        \"disag_fridge\",\n",
    "        \"cluster_small\",\n",
    "        \"cluster_big\",\n",
    "        \"lt_500\",\n",
    "        \"bet_500_1000\",\n",
    "        \"gt_1000\",\n",
    "        \"temperature_corr\",\n",
    "         [\"daily_usage_%d\" %i for i in range(1,8)],\n",
    "        \"area\",\n",
    "        \"num_rooms\",\n",
    "        \"total_occupants\",\n",
    "               ['variance','ratio_min_max', 'difference_min_max',\n",
    "                                        'ratio_difference_min_max']\n",
    "\n",
    "           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "only_month = np.hstack([[\"aggregate_%d\" %i for i in range(1,13)],\n",
    "            [\"fraction_%d\" %i for i in range(1,25)],\n",
    "         \"autocorr\",\n",
    "         \"max_seasonal_12\",\n",
    "        \"stdev_seasonal_12\",\n",
    "        \"max_trend_12\",\n",
    "        \"stdev_trend_12\",\n",
    "        \"max_seasonal_daily\",\n",
    "        \"stdev_seasonal_daily\",\n",
    "        \"max_trend_daily\",\n",
    "        \"stdev_trend_daily\",\n",
    "         \"max_seasonal_weekly\",\n",
    "        \"stdev_seasonal_weekly\",\n",
    "        \"max_trend_weekly\",\n",
    "        \"stdev_trend_weekly\",\n",
    "        \"disag_fridge\",\n",
    "        \"cluster_small\",\n",
    "        \"cluster_big\",\n",
    "        \"lt_500\",\n",
    "        \"bet_500_1000\",\n",
    "        \"gt_1000\",\n",
    "        \"temperature_corr\",\n",
    "         [\"daily_usage_%d\" %i for i in range(1,8)],\n",
    "        ['variance','ratio_min_max', 'difference_min_max',\n",
    "                                        'ratio_difference_min_max']\n",
    "\n",
    "           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def plus_L_minus_R(features, max_k, criterion_func, L=3, R=2, print_steps=False):\n",
    "    \"\"\"\n",
    "    Implementation of a \"Plus l take away r\" algorithm.\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        features (list): The feature space as a list of features.\n",
    "        max_k: Termination criterion; the size of the returned feature subset.\n",
    "        criterion_func (function): Function that is used to evaluate the\n",
    "            performance of the feature subset.\n",
    "        L (int): Number of features added per iteration.\n",
    "        R (int): Number of features removed per iteration.\n",
    "        print_steps (bool): Prints the algorithm procedure if True.\n",
    "    \n",
    "    Returns the selected feature subset, a list of features of length max_k.\n",
    "\n",
    "    \"\"\"\n",
    "    assert(L != R), 'L must be != R to avoid an infinite loop'\n",
    "\n",
    "    ############################\n",
    "    ### +L -R for case L > R ###\n",
    "    ############################\n",
    "\n",
    "    if L > R:\n",
    "        feat_sub = []\n",
    "        k = 0\n",
    "\n",
    "        # Initialization\n",
    "        while True:\n",
    "\n",
    "            # +L (Inclusion)\n",
    "            if print_steps:\n",
    "                print('\\nInclusion from features', features)\n",
    "            for i in range(L):\n",
    "                if len(features) > 0:\n",
    "                    crit_func_max = criterion_func(feat_sub + [features[0]])\n",
    "                    best_feat = features[0]\n",
    "                    if len(features) > 1:\n",
    "                        for x in features[1:]:\n",
    "                            crit_func_eval = criterion_func(feat_sub + [x])\n",
    "                            if crit_func_eval > crit_func_max:\n",
    "                                crit_func_max = crit_func_eval\n",
    "                                best_feat = x\n",
    "                    features.remove(best_feat)\n",
    "                    feat_sub.append(best_feat)\n",
    "                    if print_steps:\n",
    "                        print('include: {} -> feature_subset: {} Accuracy: {}'.format(best_feat, feat_sub, crit_func_max))\n",
    "\n",
    "            # -R (Exclusion)\n",
    "            if print_steps:\n",
    "                print('\\nExclusion from feature_subset', feat_sub)\n",
    "            for i in range(R):\n",
    "                if len(features) + len(feat_sub) > max_k:\n",
    "                    worst_feat = len(feat_sub)-1\n",
    "                    worst_feat_val = feat_sub[worst_feat]\n",
    "                    crit_func_max = criterion_func(feat_sub[:-1])\n",
    "\n",
    "                    for j in reversed(range(0,len(feat_sub)-1)):\n",
    "                        crit_func_eval = criterion_func(feat_sub[:j] + feat_sub[j+1:])\n",
    "                        if crit_func_eval > crit_func_max:\n",
    "                            worst_feat, crit_func_max = j, crit_func_eval\n",
    "                            worst_feat_val = feat_sub[worst_feat]\n",
    "                    del feat_sub[worst_feat]\n",
    "                    if print_steps:\n",
    "                        print('exclude: {} -> feature subset: {} Accuracy: {}'.format(worst_feat_val, feat_sub, crit_func_max))\n",
    "\n",
    "\n",
    "            # Termination condition\n",
    "            k = len(feat_sub)\n",
    "            if k == max_k:\n",
    "                break\n",
    "\n",
    "        return feat_sub\n",
    "\n",
    "    ############################\n",
    "    ### +L -R for case L < R ###\n",
    "    ############################\n",
    "\n",
    "    else:\n",
    "        # Initialization\n",
    "        feat_sub = deepcopy(features)\n",
    "        k = len(feat_sub)\n",
    "        i = 0\n",
    "        count = 0\n",
    "        while True:\n",
    "            count += 1\n",
    "            # Exclusion step\n",
    "            removed_feats = []\n",
    "            if print_steps:\n",
    "                print('\\nExclusion from feature subset', feat_sub)\n",
    "            for i in range(R):\n",
    "                if len(feat_sub) > max_k:\n",
    "                    worst_feat = len(feat_sub)-1\n",
    "                    worst_feat_val = feat_sub[worst_feat]\n",
    "                    crit_func_max = criterion_func(feat_sub[:-1])\n",
    "\n",
    "                    for i in reversed(range(0,len(feat_sub)-1)):\n",
    "                        crit_func_eval = criterion_func(feat_sub[:i] + feat_sub[i+1:])\n",
    "                        if crit_func_eval > crit_func_max:\n",
    "                            worst_feat, crit_func_max = i, crit_func_eval\n",
    "                            worst_feat_val = feat_sub[worst_feat]\n",
    "                    removed_feats.append(feat_sub.pop(worst_feat))\n",
    "            if print_steps:\n",
    "                print('exclude: {} -> feature subset: {} Accuracy: {}'.format(removed_feats, feat_sub, crit_func_max))\n",
    "\n",
    "            # +L (Inclusion)\n",
    "            included_feats = []\n",
    "            if len(feat_sub) != max_k:\n",
    "                for i in range(L):\n",
    "                    if len(removed_feats) > 0:\n",
    "                        crit_func_max = criterion_func(feat_sub + [removed_feats[0]])\n",
    "                        best_feat = removed_feats[0]\n",
    "                        if len(removed_feats) > 1:\n",
    "                            for x in removed_feats[1:]:\n",
    "                                crit_func_eval = criterion_func(feat_sub + [x])\n",
    "                                if crit_func_eval > crit_func_max:\n",
    "                                    crit_func_max = crit_func_eval\n",
    "                                    best_feat = x\n",
    "                        removed_feats.remove(best_feat)\n",
    "                        feat_sub.append(best_feat)\n",
    "                        included_feats.append(best_feat)\n",
    "                if print_steps:\n",
    "                    print('\\nInclusion from removed features', removed_feats)\n",
    "                    print('include: {} -> feature_subset: {} Accuracy: {}'.format(included_feats, feat_sub, crit_func_max))\n",
    "\n",
    "            # Termination condition\n",
    "            k = len(feat_sub)\n",
    "            if k == max_k:\n",
    "                break\n",
    "            if count >= 30:\n",
    "                break\n",
    "        return feat_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "appliance=\"fridge\"\n",
    "k=2\n",
    "best = plus_L_minus_R(features=a.tolist(), max_k=25,L=30, R=5,\n",
    "                      criterion_func=criterion_function, print_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "hvac\n",
      "********************\n",
      "++++++++++++++++++++\n",
      "2\n",
      "include: variance -> feature_subset: ['variance']. Accuracy: 80.2629058813\n",
      "include: stdev_trend_weekly -> feature_subset: ['variance', 'stdev_trend_weekly']. Accuracy: 79.7712351977\n",
      "include: stdev_seasonal_weekly -> feature_subset: ['variance', 'stdev_trend_weekly', 'stdev_seasonal_weekly']. Accuracy: 82.9298116073\n",
      "include: daily_usage_5 -> feature_subset: ['variance', 'stdev_trend_weekly', 'stdev_seasonal_weekly', 'daily_usage_5']. Accuracy: 82.5776992993\n",
      "include: daily_usage_2 -> feature_subset: ['variance', 'stdev_trend_weekly', 'stdev_seasonal_weekly', 'daily_usage_5', 'daily_usage_2']. Accuracy: 82.4684879398\n",
      "include: daily_usage_1 -> feature_subset: ['variance', 'stdev_trend_weekly', 'stdev_seasonal_weekly', 'daily_usage_5', 'daily_usage_2', 'daily_usage_1']. Accuracy: 82.1555828414\n",
      "include: aggregate_9 -> feature_subset: ['variance', 'stdev_trend_weekly', 'stdev_seasonal_weekly', 'daily_usage_5', 'daily_usage_2', 'daily_usage_1', 'aggregate_9']. Accuracy: 82.2141641514\n",
      "include: ratio_min_max -> feature_subset: ['variance', 'stdev_trend_weekly', 'stdev_seasonal_weekly', 'daily_usage_5', 'daily_usage_2', 'daily_usage_1', 'aggregate_9', 'ratio_min_max']. Accuracy: 84.0192970371\n",
      "include: aggregate_8 -> feature_subset: ['variance', 'stdev_trend_weekly', 'stdev_seasonal_weekly', 'daily_usage_5', 'daily_usage_2', 'daily_usage_1', 'aggregate_9', 'ratio_min_max', 'aggregate_8']. Accuracy: 83.4068404171\n",
      "include: aggregate_6 -> feature_subset: ['variance', 'stdev_trend_weekly', 'stdev_seasonal_weekly', 'daily_usage_5', 'daily_usage_2', 'daily_usage_1', 'aggregate_9', 'ratio_min_max', 'aggregate_8', 'aggregate_6']. Accuracy: 83.3181439132\n",
      "include: autocorr -> feature_subset: ['variance', 'stdev_trend_weekly', 'stdev_seasonal_weekly', 'daily_usage_5', 'daily_usage_2', 'daily_usage_1', 'aggregate_9', 'ratio_min_max', 'aggregate_8', 'aggregate_6', 'autocorr']. Accuracy: 85.4379542224\n",
      "include: ratio_difference_min_max -> feature_subset: ['variance', 'stdev_trend_weekly', 'stdev_seasonal_weekly', 'daily_usage_5', 'daily_usage_2', 'daily_usage_1', 'aggregate_9', 'ratio_min_max', 'aggregate_8', 'aggregate_6', 'autocorr', 'ratio_difference_min_max']. Accuracy: 85.5575794511\n",
      "include: difference_min_max -> feature_subset: ['variance', 'stdev_trend_weekly', 'stdev_seasonal_weekly', 'daily_usage_5', 'daily_usage_2', 'daily_usage_1', 'aggregate_9', 'ratio_min_max', 'aggregate_8', 'aggregate_6', 'autocorr', 'ratio_difference_min_max', 'difference_min_max']. Accuracy: 85.0483209047\n",
      "include: gt_1000 -> feature_subset: ['variance', 'stdev_trend_weekly', 'stdev_seasonal_weekly', 'daily_usage_5', 'daily_usage_2', 'daily_usage_1', 'aggregate_9', 'ratio_min_max', 'aggregate_8', 'aggregate_6', 'autocorr', 'ratio_difference_min_max', 'difference_min_max', 'gt_1000']. Accuracy: 84.941676114\n",
      "include: aggregate_12 -> feature_subset: ['variance', 'stdev_trend_weekly', 'stdev_seasonal_weekly', 'daily_usage_5', 'daily_usage_2', 'daily_usage_1', 'aggregate_9', 'ratio_min_max', 'aggregate_8', 'aggregate_6', 'autocorr', 'ratio_difference_min_max', 'difference_min_max', 'gt_1000', 'aggregate_12']. Accuracy: 84.3804057233\n",
      "include: cluster_big -> feature_subset: ['variance', 'stdev_trend_weekly', 'stdev_seasonal_weekly', 'daily_usage_5', 'daily_usage_2', 'daily_usage_1', 'aggregate_9', 'ratio_min_max', 'aggregate_8', 'aggregate_6', 'autocorr', 'ratio_difference_min_max', 'difference_min_max', 'gt_1000', 'aggregate_12', 'cluster_big']. Accuracy: 85.2388505119\n",
      "include: aggregate_3 -> feature_subset: ['variance', 'stdev_trend_weekly', 'stdev_seasonal_weekly', 'daily_usage_5', 'daily_usage_2', 'daily_usage_1', 'aggregate_9', 'ratio_min_max', 'aggregate_8', 'aggregate_6', 'autocorr', 'ratio_difference_min_max', 'difference_min_max', 'gt_1000', 'aggregate_12', 'cluster_big', 'aggregate_3']. Accuracy: 85.5105377306"
     ]
    }
   ],
   "source": [
    "for appliance in [\"fridge\",\"wm\",\"light\",\"dr\",\"dw\"]:\n",
    "#for appliance in [\"hvac\"]:\n",
    "    print \"*\"*20\n",
    "    print appliance\n",
    "    print \"*\"*20\n",
    "    for k in range(2, 8):\n",
    "        print \"+\"*20\n",
    "        print k\n",
    "        best=seq_forw_select(features=a.tolist(), max_k=25,\n",
    "                      criterion_func=criterion_function, print_steps=True)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature = ['daily_usage_1', 'aggregate_12', 'bet_500_1000', 'aggregate_11', 'daily_usage_3', 'aggregate_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = create_predictions('wm',feature,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "errors = {}\n",
    "for i in range(1, 13):\n",
    "    errors[i] = percentage_error(temp[i][\"gt\"], temp[i][\"pred\"])\n",
    "error_df = pd.DataFrame(errors)\n",
    "accur_df = 100-error_df\n",
    "accur_df[accur_df<0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(accur_df.dropna().mean(axis=1).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_homes[\"wm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([  94,  370,  545,  624, 2156, 2242, 2470, 2814, 3367, 3456, 3723,\n",
       "            3967, 5357, 7769, 9654, 9922, 9934],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accur_df.dropna().mean(axis=1).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  94,  370,  545,  624, 2156, 2242, 2470, 2814, 3367, 3456, 3723,\n",
       "       3967, 5357, 7769, 9654, 9922, 9934])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_homes[\"wm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.424884</td>\n",
       "      <td>28.866257</td>\n",
       "      <td>92.898331</td>\n",
       "      <td>50.488661</td>\n",
       "      <td>59.497194</td>\n",
       "      <td>88.115325</td>\n",
       "      <td>65.179397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.953375</td>\n",
       "      <td>52.536167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>97.901964</td>\n",
       "      <td>94.057382</td>\n",
       "      <td>84.948467</td>\n",
       "      <td>79.105185</td>\n",
       "      <td>98.158677</td>\n",
       "      <td>99.437912</td>\n",
       "      <td>81.937896</td>\n",
       "      <td>90.930729</td>\n",
       "      <td>61.403339</td>\n",
       "      <td>99.061640</td>\n",
       "      <td>58.652891</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>46.020431</td>\n",
       "      <td>44.988109</td>\n",
       "      <td>46.226699</td>\n",
       "      <td>60.529976</td>\n",
       "      <td>43.700783</td>\n",
       "      <td>35.711459</td>\n",
       "      <td>84.671711</td>\n",
       "      <td>24.630623</td>\n",
       "      <td>60.646589</td>\n",
       "      <td>36.785390</td>\n",
       "      <td>90.666716</td>\n",
       "      <td>53.247304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.436283</td>\n",
       "      <td>47.483045</td>\n",
       "      <td>53.320942</td>\n",
       "      <td>66.306821</td>\n",
       "      <td>79.350594</td>\n",
       "      <td>50.438898</td>\n",
       "      <td>63.565543</td>\n",
       "      <td>91.500659</td>\n",
       "      <td>85.431732</td>\n",
       "      <td>88.970184</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>84.797694</td>\n",
       "      <td>88.634862</td>\n",
       "      <td>82.843653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.293848</td>\n",
       "      <td>94.912676</td>\n",
       "      <td>99.930704</td>\n",
       "      <td>18.685505</td>\n",
       "      <td>59.393439</td>\n",
       "      <td>69.865538</td>\n",
       "      <td>82.451663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>98.212052</td>\n",
       "      <td>60.618599</td>\n",
       "      <td>91.226561</td>\n",
       "      <td>68.889830</td>\n",
       "      <td>58.288972</td>\n",
       "      <td>64.990825</td>\n",
       "      <td>91.454011</td>\n",
       "      <td>94.577051</td>\n",
       "      <td>88.302875</td>\n",
       "      <td>55.349210</td>\n",
       "      <td>58.693093</td>\n",
       "      <td>70.700961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>26.804586</td>\n",
       "      <td>30.144605</td>\n",
       "      <td>55.927099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>81.012073</td>\n",
       "      <td>77.142305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.463076</td>\n",
       "      <td>92.797747</td>\n",
       "      <td>50.116839</td>\n",
       "      <td>86.614088</td>\n",
       "      <td>38.552042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2814</th>\n",
       "      <td>58.049857</td>\n",
       "      <td>61.686476</td>\n",
       "      <td>35.057595</td>\n",
       "      <td>76.589589</td>\n",
       "      <td>58.112607</td>\n",
       "      <td>82.768680</td>\n",
       "      <td>91.154992</td>\n",
       "      <td>88.810455</td>\n",
       "      <td>45.312904</td>\n",
       "      <td>78.983250</td>\n",
       "      <td>79.382190</td>\n",
       "      <td>17.382190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3367</th>\n",
       "      <td>90.598749</td>\n",
       "      <td>88.652190</td>\n",
       "      <td>57.265813</td>\n",
       "      <td>84.879105</td>\n",
       "      <td>90.408675</td>\n",
       "      <td>70.535319</td>\n",
       "      <td>60.216831</td>\n",
       "      <td>88.078489</td>\n",
       "      <td>54.735209</td>\n",
       "      <td>75.155630</td>\n",
       "      <td>99.031968</td>\n",
       "      <td>34.386181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3456</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>56.924489</td>\n",
       "      <td>48.373307</td>\n",
       "      <td>97.150129</td>\n",
       "      <td>83.383622</td>\n",
       "      <td>49.547788</td>\n",
       "      <td>92.585802</td>\n",
       "      <td>95.953168</td>\n",
       "      <td>18.249217</td>\n",
       "      <td>99.578846</td>\n",
       "      <td>73.326293</td>\n",
       "      <td>87.537180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3723</th>\n",
       "      <td>99.832433</td>\n",
       "      <td>73.145089</td>\n",
       "      <td>77.275400</td>\n",
       "      <td>83.795376</td>\n",
       "      <td>90.837177</td>\n",
       "      <td>17.326474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>85.574165</td>\n",
       "      <td>66.666615</td>\n",
       "      <td>66.732703</td>\n",
       "      <td>78.650216</td>\n",
       "      <td>68.960984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3967</th>\n",
       "      <td>87.219609</td>\n",
       "      <td>72.721640</td>\n",
       "      <td>71.536017</td>\n",
       "      <td>42.894276</td>\n",
       "      <td>51.115840</td>\n",
       "      <td>93.307678</td>\n",
       "      <td>52.723165</td>\n",
       "      <td>82.051762</td>\n",
       "      <td>90.737060</td>\n",
       "      <td>88.371071</td>\n",
       "      <td>78.217154</td>\n",
       "      <td>94.375046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5357</th>\n",
       "      <td>87.837305</td>\n",
       "      <td>87.619406</td>\n",
       "      <td>90.988462</td>\n",
       "      <td>97.768937</td>\n",
       "      <td>66.575570</td>\n",
       "      <td>55.715397</td>\n",
       "      <td>99.240751</td>\n",
       "      <td>93.519909</td>\n",
       "      <td>73.288259</td>\n",
       "      <td>44.842444</td>\n",
       "      <td>81.930377</td>\n",
       "      <td>74.127007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7769</th>\n",
       "      <td>97.611183</td>\n",
       "      <td>95.641585</td>\n",
       "      <td>80.225676</td>\n",
       "      <td>91.840752</td>\n",
       "      <td>92.682869</td>\n",
       "      <td>94.253415</td>\n",
       "      <td>85.053961</td>\n",
       "      <td>70.385270</td>\n",
       "      <td>93.916551</td>\n",
       "      <td>84.772997</td>\n",
       "      <td>99.284937</td>\n",
       "      <td>99.160768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9654</th>\n",
       "      <td>40.676212</td>\n",
       "      <td>31.113636</td>\n",
       "      <td>37.402734</td>\n",
       "      <td>73.813510</td>\n",
       "      <td>34.554901</td>\n",
       "      <td>43.706520</td>\n",
       "      <td>37.289316</td>\n",
       "      <td>55.931934</td>\n",
       "      <td>54.309316</td>\n",
       "      <td>44.111597</td>\n",
       "      <td>34.553520</td>\n",
       "      <td>32.280144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9922</th>\n",
       "      <td>84.265144</td>\n",
       "      <td>64.691223</td>\n",
       "      <td>71.252774</td>\n",
       "      <td>70.365389</td>\n",
       "      <td>13.387510</td>\n",
       "      <td>13.836499</td>\n",
       "      <td>82.926465</td>\n",
       "      <td>80.516454</td>\n",
       "      <td>61.352970</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.742160</td>\n",
       "      <td>67.054427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9934</th>\n",
       "      <td>42.102386</td>\n",
       "      <td>60.934125</td>\n",
       "      <td>44.777340</td>\n",
       "      <td>59.826283</td>\n",
       "      <td>62.896899</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>86.056589</td>\n",
       "      <td>63.655074</td>\n",
       "      <td>72.835468</td>\n",
       "      <td>91.832185</td>\n",
       "      <td>61.385180</td>\n",
       "      <td>75.312734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             1          2          3          4          5          6   \\\n",
       "94     0.000000   0.000000  71.424884  28.866257  92.898331  50.488661   \n",
       "370   97.901964  94.057382  84.948467  79.105185  98.158677  99.437912   \n",
       "545   46.020431  44.988109  46.226699  60.529976  43.700783  35.711459   \n",
       "624    0.000000  48.436283  47.483045  53.320942  66.306821  79.350594   \n",
       "2156  84.797694  88.634862  82.843653   0.000000   0.000000  57.293848   \n",
       "2242  98.212052  60.618599  91.226561  68.889830  58.288972  64.990825   \n",
       "2470  26.804586  30.144605  55.927099   0.000000  81.012073  77.142305   \n",
       "2814  58.049857  61.686476  35.057595  76.589589  58.112607  82.768680   \n",
       "3367  90.598749  88.652190  57.265813  84.879105  90.408675  70.535319   \n",
       "3456   0.000000  56.924489  48.373307  97.150129  83.383622  49.547788   \n",
       "3723  99.832433  73.145089  77.275400  83.795376  90.837177  17.326474   \n",
       "3967  87.219609  72.721640  71.536017  42.894276  51.115840  93.307678   \n",
       "5357  87.837305  87.619406  90.988462  97.768937  66.575570  55.715397   \n",
       "7769  97.611183  95.641585  80.225676  91.840752  92.682869  94.253415   \n",
       "9654  40.676212  31.113636  37.402734  73.813510  34.554901  43.706520   \n",
       "9922  84.265144  64.691223  71.252774  70.365389  13.387510  13.836499   \n",
       "9934  42.102386  60.934125  44.777340  59.826283  62.896899   0.000000   \n",
       "\n",
       "             7          8          9          10         11         12  \n",
       "94    59.497194  88.115325  65.179397   0.000000  37.953375  52.536167  \n",
       "370   81.937896  90.930729  61.403339  99.061640  58.652891   0.000000  \n",
       "545   84.671711  24.630623  60.646589  36.785390  90.666716  53.247304  \n",
       "624   50.438898  63.565543  91.500659  85.431732  88.970184   0.000000  \n",
       "2156  94.912676  99.930704  18.685505  59.393439  69.865538  82.451663  \n",
       "2242  91.454011  94.577051  88.302875  55.349210  58.693093  70.700961  \n",
       "2470   0.000000  90.463076  92.797747  50.116839  86.614088  38.552042  \n",
       "2814  91.154992  88.810455  45.312904  78.983250  79.382190  17.382190  \n",
       "3367  60.216831  88.078489  54.735209  75.155630  99.031968  34.386181  \n",
       "3456  92.585802  95.953168  18.249217  99.578846  73.326293  87.537180  \n",
       "3723   0.000000  85.574165  66.666615  66.732703  78.650216  68.960984  \n",
       "3967  52.723165  82.051762  90.737060  88.371071  78.217154  94.375046  \n",
       "5357  99.240751  93.519909  73.288259  44.842444  81.930377  74.127007  \n",
       "7769  85.053961  70.385270  93.916551  84.772997  99.284937  99.160768  \n",
       "9654  37.289316  55.931934  54.309316  44.111597  34.553520  32.280144  \n",
       "9922  82.926465  80.516454  61.352970   0.000000  66.742160  67.054427  \n",
       "9934  86.056589  63.655074  72.835468  91.832185  61.385180  75.312734  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accur_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11543e350>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEPCAYAAACjjWTcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115448350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m=2\n",
    "wm = 'wm_%d' %m\n",
    "feature_plot=\"area\"\n",
    "df.ix[all_homes[\"wm\"]][[feature_plot,wm]].plot(kind=\"scatter\", x=feature_plot,y=wm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = create_predictions('wm',['area'],1)\n",
    "errors = {}\n",
    "for i in range(1, 13):\n",
    "    errors[i] = percentage_error(temp[i][\"gt\"], temp[i][\"pred\"])\n",
    "error_df = pd.DataFrame(errors)\n",
    "accur_df = 100-error_df\n",
    "accur_df[accur_df<0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     75.396849\n",
       "2     54.210730\n",
       "3     70.017919\n",
       "4     76.092595\n",
       "5     67.051359\n",
       "6     72.371640\n",
       "7     61.919578\n",
       "8     52.771398\n",
       "9     49.699680\n",
       "10    49.753408\n",
       "11    51.554367\n",
       "12    57.104109\n",
       "dtype: float64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accur_df.dropna().median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
