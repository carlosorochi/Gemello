{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from degree_days import  dd\n",
    "from regional_average_contribution import  contribution\n",
    "import pandas as pd\n",
    "out_overall = pickle.load(open('../data/input/all_regions.pkl','r'))\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "train_region, test_region, test_home, appliance, transform, K = \"Austin\",\"SanDiego\", 203, \"hvac\",\"None\",3\n",
    "test_home = int(test_home)\n",
    "K = int(K)\n",
    "\n",
    "train_df = out_overall[train_region]\n",
    "test_df = out_overall[test_region]\n",
    "\n",
    "train_dd = pd.DataFrame(dd[train_region])\n",
    "test_dd = pd.DataFrame(dd[test_region])\n",
    "\n",
    "median_aggregate = {}\n",
    "for region in [train_region, test_region]:\n",
    "    median_aggregate[region] = {}\n",
    "    for month in range(1, 13):\n",
    "        median_aggregate[region][month] = out_overall[region]['aggregate_'+str(month)].median()\n",
    "\n",
    "median_aggregate_df = pd.DataFrame(median_aggregate)\n",
    "\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "start_month, end_month = 1,12\n",
    "agg_features = np.hstack([['aggregate_'+str(month) for month in range(start_month, end_month+1)],\n",
    "                         'ratio_min_max','difference_ratio_min_max','p_25','p_50','p_75','skew','kurtosis'])\n",
    "md_features = ['area','house_num_rooms']\n",
    "features = {'md_agg':np.hstack([\n",
    "            agg_features,\n",
    "            md_features\n",
    "            ]).tolist()}\n",
    "\n",
    "f_all = features['md_agg']\n",
    "\n",
    "# Find not null set of common features\n",
    "def find_com_features_train(df, home_1, home_2, featureset_max):\n",
    "    f_1 = df.ix[home_1][featureset_max].dropna()\n",
    "    f_2 = df.ix[home_2][featureset_max].dropna()\n",
    "    com_f =  np.intersect1d(f_1.index, f_2.index)\n",
    "    return com_f\n",
    "\n",
    "\n",
    "def find_distance_train_test_quick(df_train, home_1, home_2, df_test, home_test, featureset_train, featureset_max):\n",
    "    f_test = df_test.ix[home_test][featureset_max].dropna()\n",
    "    com_f =  np.intersect1d(f_test.index, featureset_train)\n",
    "    if len(com_f):\n",
    "        is_common = True\n",
    "    else:\n",
    "        is_common = False\n",
    "        return is_common, None\n",
    "\n",
    "    if len(com_f):\n",
    "        a = (df_train.ix[home_1][com_f]- df_test.ix[home_test][com_f]).abs().sum().sum()\n",
    "        b = (df_train.ix[home_2][com_f]- df_test.ix[home_test][com_f]).abs().sum().sum()\n",
    "        \n",
    "        if a<=b:\n",
    "            order = [home_1, home_2]\n",
    "        else:\n",
    "            order = [home_2, home_1]\n",
    "        return is_common, {'order':order,\n",
    "                    'num_f':len(com_f),\n",
    "                    'dist_a':a,\n",
    "                    'dist_b':b,\n",
    "                          'f':com_f}\n",
    "\n",
    "\n",
    "def find_distance_train_test(df_train, home_1, home_2, df_test, home_test, featureset_train, featureset_max):\n",
    "    f_test = df_test.ix[home_test][featureset_max].dropna()\n",
    "    com_f =  np.intersect1d(f_test.index, featureset_train)\n",
    "    if len(com_f):\n",
    "        is_common = True\n",
    "    else:\n",
    "        is_common = False\n",
    "        return is_common, None\n",
    "\n",
    "    if len(com_f):\n",
    "        a = np.linalg.norm(df_train.ix[home_1][com_f]- df_test.ix[home_test][com_f])\n",
    "        b = np.linalg.norm(df_train.ix[home_2][com_f]- df_test.ix[home_test][com_f])\n",
    "        if a<=b:\n",
    "            order = [home_1, home_2]\n",
    "        else:\n",
    "            order = [home_2, home_1]\n",
    "        return is_common, {'order':order,\n",
    "                    'num_f':len(com_f),\n",
    "                    'dist_a':a,\n",
    "                    'dist_b':b,\n",
    "                          'f':com_f}\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def scale_0_1(ser, minimum=None, maximum=None):\n",
    "    if minimum is not None:\n",
    "        pass\n",
    "    else:\n",
    "        minimum = ser.min()\n",
    "        maximum = ser.max()\n",
    "    return (ser-minimum).div(maximum-minimum)\n",
    "\n",
    "def normalise(df):\n",
    "    new_df = df.copy()\n",
    "    max_aggregate = df[[\"aggregate_%d\" % i for i in range(1, 13)]].max().max()\n",
    "    min_aggregate = df[[\"aggregate_%d\" % i for i in range(1, 13)]].min().min()\n",
    "    new_df[[\"aggregate_%d\" % i for i in range(1, 13)]] = scale_0_1(df[[\"aggregate_%d\" % i for i in range(1, 13)]], min_aggregate, max_aggregate)\n",
    "    for col in ['area','num_occupants','house_num_rooms','ratio_min_max',\n",
    "                'skew','kurtosis','variance','difference_ratio_min_max','p_25',\n",
    "               'p_50','p_75']:\n",
    "        new_df[col] = scale_0_1(df[col])\n",
    "    return new_df\n",
    "\n",
    "if transform in [\"None\",\"None-percentage\"]:\n",
    "    pass\n",
    "elif transform in [\"DD\",\"DD-percentage\"]:\n",
    "    train_df_copy = train_df.copy()\n",
    "    for month in range(1, 13):\n",
    "        # index on 0, 11\n",
    "        train_dd_month = train_dd.ix[month-1]['Total']\n",
    "        test_dd_month = test_dd.ix[month-1]['Total']\n",
    "        train_df['hvac_%d' % month] = train_df_copy['hvac_%d' % month] * test_dd_month*1. / train_dd_month\n",
    "\n",
    "        #New aggregate will be removing old HVAC and adding new HVAC!\n",
    "        train_df['aggregate_%d' %month] = train_df_copy['aggregate_%d' %month] - train_df_copy['hvac_%d' % month] + train_df['hvac_%d' % month]\n",
    "elif transform in [\"median-aggregate\",\"median-aggregate-percentage\"]:\n",
    "    train_df_copy = train_df.copy()\n",
    "    for month in range(1,13):\n",
    "        median_month = median_aggregate_df.ix[month]\n",
    "        cols_to_transform = [x for x in train_df.columns if \"_\"+str(month) in x]\n",
    "        train_df[cols_to_transform] = train_df_copy[cols_to_transform] * median_month[test_region] / median_month[train_region]\n",
    "\n",
    "elif transform in [\"regional\",\"regional-percentage\"]:\n",
    "    train_df_copy = train_df.copy()\n",
    "    for month in range(1, 13):\n",
    "\n",
    "        # index on 0, 11\n",
    "        if month in range(4,11):\n",
    "            mode='Cooling'\n",
    "        else:\n",
    "            mode='Heating'\n",
    "\n",
    "        train_dd_month = contribution[train_region][mode]['hvac']\n",
    "        test_dd_month = contribution[test_region][mode]['hvac']\n",
    "\n",
    "        train_df['hvac_%d' % month] = train_df_copy['hvac_%d' % month] * test_dd_month*1. / train_dd_month\n",
    "\n",
    "        #New aggregate will be removing old HVAC and adding new HVAC!\n",
    "        train_df['aggregate_%d' %month] = train_df_copy['aggregate_%d' %month] - train_df_copy['hvac_%d' % month] + train_df['hvac_%d' % month]\n",
    "\n",
    "\n",
    "\n",
    "elif transform==\"DD-fridge\":\n",
    "    train_df_copy = train_df.copy()\n",
    "    fridge_model = pickle.load(open('../data/input/SanDiego_fridge_dd_coef.pkl','r'))\n",
    "    for month in range(1, 13):\n",
    "        # index on 0, 11\n",
    "\n",
    "        train_cdd_month = train_dd.ix[month-1]['Cooling']\n",
    "        test_cdd_month = test_dd.ix[month-1]['Cooling']\n",
    "        for fridge_home, fridge_home_model in fridge_model.iteritems():\n",
    "            train_df.loc[fridge_home,'fridge_%d' % month] = fridge_home_model['baseline']+fridge_home_model['cdd']*test_cdd_month\n",
    "            train_df.loc[fridge_home,'aggregate_%d' %month] = train_df_copy.ix[fridge_home]['aggregate_%d' %month] - train_df_copy.ix[fridge_home]['fridge_%d' % month] + train_df.ix[fridge_home]['fridge_%d' % month]\n",
    "\n",
    "overall_df = pd.concat([train_df, test_df])\n",
    "\n",
    "normalised_df = normalise(overall_df)\n",
    "\n",
    "train_normalised_df = normalised_df.ix[train_df.index]\n",
    "test_normalised_df = normalised_df.ix[test_df.index].drop_duplicates()\n",
    "\n",
    "\n",
    "def solve_ilp(inequalities, time_limit=50):\n",
    "    from collections import defaultdict\n",
    "    import pandas as pd\n",
    "    co = defaultdict(int)\n",
    "    for ineq in inequalities:\n",
    "        lt = ineq[0]\n",
    "        gt = ineq[1]\n",
    "        co[lt]-= 1\n",
    "        co[gt]+= 1\n",
    "    co_ser = pd.Series(co)\n",
    "    co_ser.sort()\n",
    "\n",
    "    return co_ser.index.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'hvac_1', u'hvac_2', u'hvac_3', u'hvac_4', u'hvac_5', u'hvac_6',\n",
       "       u'hvac_7', u'hvac_8', u'hvac_9', u'hvac_10',\n",
       "       ...\n",
       "       u'md_available', u'full_agg_available', u'ratio_min_max',\n",
       "       u'difference_ratio_min_max', u'variance', u'skew', u'kurtosis', u'p_25',\n",
       "       u'p_50', u'p_75'],\n",
       "      dtype='object', length=133)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_df['md_available']&test_df['full_agg_available']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hvac_1                      25\n",
       "hvac_2                      21\n",
       "hvac_3                      21\n",
       "hvac_4                      21\n",
       "hvac_5                      21\n",
       "hvac_6                      21\n",
       "hvac_7                      19\n",
       "hvac_8                      18\n",
       "hvac_9                      17\n",
       "hvac_10                     16\n",
       "hvac_11                     15\n",
       "hvac_12                     15\n",
       "wm_1                         8\n",
       "wm_2                         4\n",
       "wm_3                         4\n",
       "wm_4                         4\n",
       "wm_5                         4\n",
       "wm_6                         4\n",
       "wm_7                         3\n",
       "wm_8                         3\n",
       "wm_9                         2\n",
       "wm_10                        2\n",
       "wm_11                        2\n",
       "wm_12                        2\n",
       "fridge_1                    23\n",
       "fridge_2                    20\n",
       "fridge_3                    20\n",
       "fridge_4                    20\n",
       "fridge_5                    20\n",
       "fridge_6                    20\n",
       "                            ..\n",
       "dw_8                        18\n",
       "dw_9                        17\n",
       "dw_10                       16\n",
       "dw_11                       15\n",
       "dw_12                       15\n",
       "dr_1                         0\n",
       "dr_2                         0\n",
       "dr_3                         0\n",
       "dr_4                         0\n",
       "dr_5                         0\n",
       "dr_6                         0\n",
       "dr_7                         0\n",
       "dr_8                         0\n",
       "dr_9                         0\n",
       "dr_10                        0\n",
       "dr_11                        0\n",
       "dr_12                        0\n",
       "house_num_rooms              8\n",
       "area                         8\n",
       "num_occupants                8\n",
       "md_available                42\n",
       "full_agg_available          42\n",
       "ratio_min_max               15\n",
       "difference_ratio_min_max    15\n",
       "variance                    15\n",
       "skew                        15\n",
       "kurtosis                    15\n",
       "p_25                        15\n",
       "p_50                        15\n",
       "p_75                        15\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.describe().ix['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "month_compute=1\n",
    "candidate_homes = train_normalised_df['%s_%d' %(appliance, month_compute)].dropna().index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(candidate_homes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 203,  203, 1450, 1450, 1524, 1524, 1731, 1731, 2354, 2354, 2606,\n",
       "       2606, 3687, 3687, 3864, 3864, 3938, 3938, 4495, 4495, 4934, 4934,\n",
       "       5938, 5938, 6377, 6377, 6547, 6547, 7062, 7062, 7114, 7114, 8061,\n",
       "       8061, 8342, 8342, 8574, 8574, 8733, 8733, 9213, 9213, 9585, 9585,\n",
       "       9612, 9612, 9775, 9775, 9836, 9836])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_homes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "candidate_homes = np.array(np.setdiff1d(candidate_homes, test_home))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(candidate_homes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a,b= next(combinations(candidate_homes, 2))\n",
    "a,b\n",
    "com_features = find_com_features_train(train_df, a, b, f_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aggregate_1', 'aggregate_10', 'aggregate_11', 'aggregate_12',\n",
       "       'aggregate_2', 'aggregate_3', 'aggregate_4', 'aggregate_5',\n",
       "       'aggregate_6', 'aggregate_7', 'aggregate_8', 'aggregate_9',\n",
       "       'difference_ratio_min_max', 'kurtosis', 'p_25', 'p_50', 'p_75',\n",
       "       'ratio_min_max', 'skew'], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "com_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 3.61 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit is_common, d = find_distance_train_test(train_normalised_df, a, b, test_normalised_df, test_home, com_features, f_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 3.86 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit is_common, d = find_distance_train_test_quick(train_normalised_df, a, b, test_normalised_df, test_home, com_features, f_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for month_compute in range(1, 13):\n",
    "\n",
    "    from collections import Counter, defaultdict\n",
    "    num_features_all = {}\n",
    "    ineq_dict = {}\n",
    "\n",
    "    num_features_all[appliance] = {}\n",
    "    ineq_dict[appliance] = {}\n",
    "\n",
    "    #num_features_all[appliance][month_compute] = {}\n",
    "    ineq_dict[appliance][month_compute] = {}\n",
    "\n",
    "    candidate_homes = train_normalised_df['%s_%d' %(appliance, month_compute)].dropna().index.values\n",
    "\n",
    "\n",
    "\n",
    "    #num_features_all[appliance][month_compute][test_home] = defaultdict(int)\n",
    "    from collections import defaultdict\n",
    "    import pandas as pd\n",
    "    co = defaultdict(int)\n",
    "    store_path = '../../../output/output/ineq_cross/%s_%s_%s_%s_%d_%d_%d.pkl' %(train_region,\n",
    "                                                                        test_region,\n",
    "                                                                        transform,\n",
    "                                                                        appliance,\n",
    "                                                                        month_compute,\n",
    "                                                                        test_home, K)\n",
    "    print store_path\n",
    "    if os.path.exists(store_path):\n",
    "        print \"already exists\"\n",
    "        continue\n",
    "\n",
    "\n",
    "    if not np.isnan(test_normalised_df.ix[test_home]['%s_%d' %(appliance, month_compute)]):\n",
    "        # We need to predict this value!\n",
    "        # Find candidate set, train homes which have not null for this month\n",
    "        # Now find features on pairs of homes in candidate homes\n",
    "        for a,b in combinations(candidate_homes, 2):\n",
    "            com_features = find_com_features_train(train_df, a, b, f_all)\n",
    "\n",
    "            if len(com_features):\n",
    "                # Consider a,b\n",
    "                is_common, d = find_distance_train_test(train_normalised_df, a, b, test_normalised_df, test_home, com_features, f_all)\n",
    "                if is_common:\n",
    "\n",
    "                    # Common between train and test. Can add this pair to inequalities\n",
    "                    ineq=d['order']\n",
    "                    lt = ineq[0]\n",
    "                    gt = ineq[1]\n",
    "                    co[lt]-= 1\n",
    "                    co[gt]+= 1\n",
    "                    #num_features_all[appliance][month_compute][test_home][d['num_f']]+= 1\n",
    "\n",
    "        \"\"\"\n",
    "        # Saving ineqs\n",
    "        pickle.dump(ineqs, open('../data/model/inequalities/%s_%s_%s_%s_%d_%d.pkl' %(train_region,\n",
    "                                                                        test_region,\n",
    "                                                                        transform,\n",
    "                                                                        appliance,\n",
    "                                                                        month_compute,\n",
    "                                                                        test_home),'w'))\n",
    "        \"\"\"\n",
    "        co_ser = pd.Series(co)\n",
    "        co_ser.sort()\n",
    "        ranks = co_ser.index.values.tolist()\n",
    "        if \"percentage\" in transform:\n",
    "            mean_proportion = (train_df.ix[ranks[:K]]['%s_%d' %(appliance, month_compute)]/ train_df.ix[ranks[:K]]['aggregate_%d' %(month_compute)]).mean()\n",
    "\n",
    "            pred = test_df.ix[test_home]['aggregate_%d' %month_compute]*mean_proportion\n",
    "\n",
    "        else:\n",
    "            pred = train_df.ix[ranks[:K]]['%s_%d' %(appliance, month_compute)].dropna().mean()\n",
    "        gt = test_df.ix[test_home]['%s_%d' %(appliance, month_compute)]\n",
    "        pickle.dump(pred, open(store_path,'w'))\n",
    "\n",
    "\n",
    "    else:\n",
    "        # No need to predict\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
